{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJmOu/dLxwagYsgSODiN5c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36a80f2945b94660968a3e037d3932cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65383508132747379d78390d73625ff7",
              "IPY_MODEL_0e01499355304856add3e576a082551c",
              "IPY_MODEL_f1f4fdf9643c490c8e5ca53b7919ecac"
            ],
            "layout": "IPY_MODEL_79aa879b748040f680dc941b67dedc88"
          }
        },
        "65383508132747379d78390d73625ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_383549218cc44bb0820e3422bec0c112",
            "placeholder": "​",
            "style": "IPY_MODEL_efefe172ee5e41ea9b1c3305a94d16c4",
            "value": "Epoch 29: 100%"
          }
        },
        "0e01499355304856add3e576a082551c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a82e6eb5eea454cb5a1fedbb393801f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae71887733354305981fd91b3144f51d",
            "value": 1
          }
        },
        "f1f4fdf9643c490c8e5ca53b7919ecac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1549291f2ff344efa0916e963a048d19",
            "placeholder": "​",
            "style": "IPY_MODEL_7da84ff2c62444a58dacf3c92563dd2c",
            "value": " 1/1 [00:00&lt;00:00, 23.27it/s, v_num=16, train_loss=1.730]"
          }
        },
        "79aa879b748040f680dc941b67dedc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "383549218cc44bb0820e3422bec0c112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efefe172ee5e41ea9b1c3305a94d16c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a82e6eb5eea454cb5a1fedbb393801f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae71887733354305981fd91b3144f51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1549291f2ff344efa0916e963a048d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da84ff2c62444a58dacf3c92563dd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helloitsdaksh/Transformer_from_Scratch/blob/main/Decoder_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqqBEyRcmKjb",
        "outputId": "02ecedcd-475b-4b65-b104-e2ca7c167fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting torchview\n",
            "  Downloading torchview-0.2.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1+cu124)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n",
            "Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchview, torchinfo, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz, torchmetrics, pytorch-lightning, lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-2.5.0.post0 lightning-utilities-0.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.0.post0 torchinfo-1.8.0 torchmetrics-1.6.1 torchview-0.2.6 torchviz-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install lightning torchinfo torchviz torchview"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ## torch let's us create tensors and also provides helper functions\n",
        "import torch.nn as nn ## torch.nn gives us nn.Module(), nn.Embedding() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us the softmax() and argmax()\n",
        "from torch.optim import Adam ## We will use the Adam optimizer, which is, essentially,\n",
        "                             ## a slightly less stochastic version of stochastic gradient descent.\n",
        "from torch.utils.data import TensorDataset, DataLoader ## We'll store our data in DataLoaders\n",
        "\n",
        "import lightning as L ## Lightning makes it easier to write, optimize and scale our code"
      ],
      "metadata": {
        "id": "1yitqs7rnycL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# **Define Constants** #\n",
        "# ABIT COMPLEX\n",
        "# BLOCK_SIZE = 8  # Context window size\n",
        "# BATCH_SIZE = 4  # Number of sequences per batch (B)\n",
        "# MAX_LEN = 10  # Maximum sequence length for positional encoding (T)\n",
        "# N_EMBD = 8  # Embedding dimension (C) d_model\n",
        "# NUM_HEADS = 4 # 2 heads\n",
        "# HEAD_SIZE = N_EMBD // NUM_HEADS  # Each head gets a fraction of embedding size\n",
        "# DROPOUT_RATE = 0.2\n",
        "# NUM_LAYERS = 5\n",
        "# LEARNING_RATE = 0.0001\n",
        "\n",
        "#SIMPLE MODEL\n",
        "BLOCK_SIZE = 4 # Context window size\n",
        "BATCH_SIZE = 4  # Number of sequences per batch (B)\n",
        "MAX_LEN = 4  # Maximum sequence length for positional encoding (T)\n",
        "N_EMBD = 2  # Embedding dimension (C) d_model\n",
        "NUM_HEADS = 2 # 2 heads\n",
        "HEAD_SIZE = N_EMBD // NUM_HEADS  # Each head gets a fraction of embedding size\n",
        "DROPOUT_RATE = 0.1\n",
        "NUM_LAYERS = 2\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "\n",
        "# Sample Text\n",
        "text = \"\"\"<SOS> I Love Transformers <EOS>\"\"\"\n",
        "\n",
        "# Correct regex pattern\n",
        "word_tokens = re.findall(r\"<EOS>|<SOS>|[\\w]+|[^\\w\\s]\", text)\n",
        "SPECIAL_TOKENS = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "word_tokens.extend(SPECIAL_TOKENS)  # Add special tokens\n",
        "\n",
        "# **Create Vocabulary**\n",
        "token_to_id = {w: i for i, w in enumerate(sorted(set(word_tokens)))}\n",
        "id_to_token = {i: w for w, i in token_to_id.items()}\n",
        "\n",
        "# **Update VOCAB_SIZE Dynamically**\n",
        "VOCAB_SIZE = len(token_to_id)  # Now we set the actual vocab size\n",
        "\n",
        "# **Encode Text as Token IDs**\n",
        "encoded_data = torch.tensor([token_to_id[w] for w in word_tokens], dtype=torch.long)\n",
        "\n",
        "# **Train-Validation Split**\n",
        "n = int(0.9 * len(encoded_data))\n",
        "train_data = encoded_data[:n]\n",
        "# val_data = encoded_data[n:]\n",
        "\n",
        "print(f\"Vocabulary Size: {VOCAB_SIZE}\")\n",
        "print(f\"Context Window Size (BLOCK_SIZE): {BLOCK_SIZE}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Max Sequence Length: {MAX_LEN}\")\n",
        "print(f\"Embedding Dimension (N_EMBD): {N_EMBD}\")\n",
        "\n",
        "# **Custom Dataset Class**\n",
        "class WordDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - BLOCK_SIZE  # Ensure valid sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx : idx + BLOCK_SIZE]  # Context window\n",
        "        y = self.data[idx + 1 : idx + BLOCK_SIZE + 1]  # Next word target\n",
        "\n",
        "        # Pad sequences to match MAX_LEN\n",
        "        pad_token = token_to_id[\"<PAD>\"]\n",
        "        x_padded = torch.cat([x, torch.full((MAX_LEN - len(x),), pad_token, dtype=torch.long)], dim=0)\n",
        "        y_padded = torch.cat([y, torch.full((MAX_LEN - len(y),), pad_token, dtype=torch.long)], dim=0)\n",
        "\n",
        "        return x_padded, y_padded\n",
        "\n",
        "# **Create DataLoader**\n",
        "train_dataset = WordDataset(train_data)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# val_dataset = WordDataset(val_data)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# **Test DataLoader**\n",
        "sample_x, sample_y = next(iter(train_loader))\n",
        "\n",
        "print(\"\\nSample Input Batch (x):\", sample_x)\n",
        "print(\"Decoded x:\", [[id_to_token[i.item()] for i in row] for row in sample_x])\n",
        "\n",
        "print(\"\\nSample Target Batch (y):\", sample_y)\n",
        "print(\"Decoded y:\", [[id_to_token[i.item()] for i in row] for row in sample_y])"
      ],
      "metadata": {
        "id": "VspF_RmHnQOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e9e480-7e74-4004-e14f-f83e617ba4c3"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 6\n",
            "Context Window Size (BLOCK_SIZE): 4\n",
            "Batch Size: 4\n",
            "Max Sequence Length: 4\n",
            "Embedding Dimension (N_EMBD): 2\n",
            "\n",
            "Sample Input Batch (x): tensor([[4, 5, 0, 1],\n",
            "        [3, 4, 5, 0],\n",
            "        [2, 3, 4, 5]])\n",
            "Decoded x: [['Love', 'Transformers', '<EOS>', '<PAD>'], ['I', 'Love', 'Transformers', '<EOS>'], ['<SOS>', 'I', 'Love', 'Transformers']]\n",
            "\n",
            "Sample Target Batch (y): tensor([[5, 0, 1, 2],\n",
            "        [4, 5, 0, 1],\n",
            "        [3, 4, 5, 0]])\n",
            "Decoded y: [['Transformers', '<EOS>', '<PAD>', '<SOS>'], ['Love', 'Transformers', '<EOS>', '<PAD>'], ['I', 'Love', 'Transformers', '<EOS>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Position Embeddings"
      ],
      "metadata": {
        "id": "Fs0Remaa3bGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.fx import symbolic_trace\n",
        "from torchinfo import summary\n",
        "\n",
        "# **Position Encoding Class**\n",
        "class PositionEncoding(nn.Module):\n",
        "    def __init__(self, n_embd=N_EMBD, max_len=MAX_LEN):\n",
        "        super().__init__()\n",
        "\n",
        "        # Position encoding matrix: (T, C)\n",
        "        pe = torch.zeros(max_len, N_EMBD)\n",
        "        # print(f\"Position Encoding Matrix (Before Training):\\n{pe}\\n\")\n",
        "        # Position indices: (T, 1)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        # print(f\"Position Indices (Before Training):\\n{position}\\n\")\n",
        "\n",
        "        # Embedding index: (C/2) for sine/cosine calculation\n",
        "        embedding_index = torch.arange(start=0, end=N_EMBD, step=2).float()\n",
        "        # print(f\"Embedding Index (Before Training):\\n{embedding_index}\\n\")\n",
        "\n",
        "        # Compute division term: (C/2)\n",
        "        div_term = 1 / torch.tensor(10000.0) ** (embedding_index / N_EMBD)\n",
        "        # print(f\"Division Term (Before Training):\\n{div_term}\\n\")\n",
        "\n",
        "        # Compute sine for even indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # print(f\"Sine Matrix:\\n{pe[:, 0::2]}\\n\")\n",
        "\n",
        "        # Compute cosine for odd indices\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        # print(f\"Cosine Matrix:\\n{pe[:, 1::2]}\\n\")\n",
        "\n",
        "        # Print final positional encoding matrix for verification\n",
        "        # print(f\"Final position encoding matrix:\\n{pe}\\n\")\n",
        "\n",
        "        # Store position encodings without making them trainable\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, word_embeddings):\n",
        "        \"\"\"\n",
        "        Adds positional encoding to word embeddings.\n",
        "        Shapes:\n",
        "        - word_embeddings: (B, T, C)\n",
        "        - position encoding: (T, C) → Needs to be reshaped for broadcasting\n",
        "        - final output: (B, T, C)\n",
        "        \"\"\"\n",
        "        return word_embeddings + self.pe[:word_embeddings.size(1), :].unsqueeze(0)\n",
        "        # Ensures (B, T, C) + (1, T, C) for correct broadcasting\n",
        "\n",
        "# **Position Embedding Helper**\n",
        "def position_embedding_helper(sample_x):\n",
        "    we = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=N_EMBD)\n",
        "    pe = PositionEncoding(n_embd=N_EMBD, max_len=MAX_LEN)\n",
        "\n",
        "    word_embeddings = we(sample_x)  # Shape: (B, T, N_EMBD)\n",
        "    print(f\"\\n[Word Embeddings (Before Position Encoding)]\\nShape: {word_embeddings.shape}\\n{word_embeddings}\\n\")\n",
        "\n",
        "    # Apply Position Encoding\n",
        "    position_encoded_embeddings = pe(word_embeddings)\n",
        "\n",
        "    print(f\"\\n[Final Position-Encoded Word Embeddings]\\nShape: {position_encoded_embeddings.shape}\\n{position_encoded_embeddings}\\n\")\n",
        "\n",
        "\n",
        "def position_embedding_graph():\n",
        "    from torchview import draw_graph\n",
        "    pe_model = PositionEncoding(n_embd=N_EMBD, max_len=MAX_LEN)\n",
        "    input_size = (BATCH_SIZE, MAX_LEN, N_EMBD)\n",
        "    model_graph = draw_graph(pe_model, input_size=input_size, expand_nested=True)\n",
        "    return model_graph"
      ],
      "metadata": {
        "id": "lHsFzHU32bwq"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_graph = position_embedding_graph()\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "fMJLIGUBGHL5",
        "outputId": "c9a39659-42d0-44f8-b5d9-d3f02f2bcd85"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: model Pages: 1 -->\n<svg width=\"245pt\" height=\"186pt\"\n viewBox=\"0.00 0.00 245.00 186.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 182)\">\n<title>model</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-182 241,-182 241,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"192.5,-178 44.5,-178 44.5,-146 192.5,-146 192.5,-178\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-146 44.5,-178 127.5,-178 127.5,-146 44.5,-146\"/>\n<text text-anchor=\"start\" x=\"49.5\" y=\"-165\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"64.5\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"127.5,-146 127.5,-178 192.5,-178 192.5,-146 127.5,-146\"/>\n<text text-anchor=\"start\" x=\"132.5\" y=\"-159.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"237,-110 0,-110 0,-68 237,-68 237,-110\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-68 0.5,-110 107.5,-110 107.5,-68 0.5,-68\"/>\n<text text-anchor=\"start\" x=\"5.5\" y=\"-92\" font-family=\"Linux libertine\" font-size=\"10.00\">PositionEncoding</text>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-81\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"107.5,-89 107.5,-110 166.5,-110 166.5,-89 107.5,-89\"/>\n<text text-anchor=\"start\" x=\"118.5\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"166.5,-89 166.5,-110 237.5,-110 237.5,-89 166.5,-89\"/>\n<text text-anchor=\"start\" x=\"171.5\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"107.5,-68 107.5,-89 166.5,-89 166.5,-68 107.5,-68\"/>\n<text text-anchor=\"start\" x=\"112.5\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"166.5,-68 166.5,-89 237.5,-89 237.5,-68 166.5,-68\"/>\n<text text-anchor=\"start\" x=\"171.5\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M118.5,-145.94C118.5,-138.45 118.5,-129.12 118.5,-120.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"122,-120.16 118.5,-110.16 115,-120.16 122,-120.16\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"195.5,-32 41.5,-32 41.5,0 195.5,0 195.5,-32\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"41.5,0 41.5,-32 130.5,-32 130.5,0 41.5,0\"/>\n<text text-anchor=\"start\" x=\"46.5\" y=\"-19\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"64.5\" y=\"-8\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130.5,0 130.5,-32 195.5,-32 195.5,0 130.5,0\"/>\n<text text-anchor=\"start\" x=\"135.5\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2)</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M118.5,-67.84C118.5,-59.89 118.5,-50.66 118.5,-42.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"122,-42.24 118.5,-32.24 115,-42.24 122,-42.24\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d3d1661bc50>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position_embedding_helper(sample_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsWYAmzhY2gL",
        "outputId": "639bffcf-f747-43e3-f694-9eccde4697c4"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Word Embeddings (Before Position Encoding)]\n",
            "Shape: torch.Size([3, 4, 2])\n",
            "tensor([[[-1.2776, -0.6300],\n",
            "         [ 0.2694,  0.7482],\n",
            "         [ 0.0859,  0.1861],\n",
            "         [ 0.6757,  0.1313]],\n",
            "\n",
            "        [[ 2.1010,  1.4371],\n",
            "         [-1.2776, -0.6300],\n",
            "         [ 0.2694,  0.7482],\n",
            "         [ 0.0859,  0.1861]],\n",
            "\n",
            "        [[ 0.0182, -2.2498],\n",
            "         [ 2.1010,  1.4371],\n",
            "         [-1.2776, -0.6300],\n",
            "         [ 0.2694,  0.7482]]], grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "\n",
            "[Final Position-Encoded Word Embeddings]\n",
            "Shape: torch.Size([3, 4, 2])\n",
            "tensor([[[-1.2776,  0.3700],\n",
            "         [ 1.1109,  1.2885],\n",
            "         [ 0.9952, -0.2301],\n",
            "         [ 0.8168, -0.8587]],\n",
            "\n",
            "        [[ 2.1010,  2.4371],\n",
            "         [-0.4361, -0.0897],\n",
            "         [ 1.1787,  0.3321],\n",
            "         [ 0.2270, -0.8039]],\n",
            "\n",
            "        [[ 0.0182, -1.2498],\n",
            "         [ 2.9425,  1.9774],\n",
            "         [-0.3683, -1.0461],\n",
            "         [ 0.4106, -0.2418]]], grad_fn=<AddBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "9RTisGYE3Y-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# **Single Attention Head**\n",
        "class Head(nn.Module):\n",
        "    \"\"\"Single self-attention head for Multi-Head Attention.\n",
        "\n",
        "    Args:\n",
        "        head_size (int): The size of each attention head (N_EMBD / NUM_HEADS).\n",
        "        dropout (float, optional): Dropout rate for regularization. Defaults to DROPOUT_RATE.\n",
        "\n",
        "    Attributes:\n",
        "        W_q (nn.Linear): Linear transformation for query matrix.\n",
        "        W_k (nn.Linear): Linear transformation for key matrix.\n",
        "        W_v (nn.Linear): Linear transformation for value matrix.\n",
        "        scale (float): Scaling factor for dot-product attention.\n",
        "        dropout (nn.Dropout): Dropout layer for attention scores.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        self.W_q = nn.Linear(in_features=N_EMBD, out_features=head_size, bias=False)\n",
        "        self.W_k = nn.Linear(in_features=N_EMBD, out_features=head_size, bias=False)\n",
        "        self.W_v = nn.Linear(in_features=N_EMBD, out_features=head_size, bias=False)\n",
        "\n",
        "        self.scale = head_size ** -0.5  # Scale factor for dot-product attention\n",
        "        self.dropout = nn.Dropout(dropout)  # Optional dropout\n",
        "        # print(f\"Dropout Rate Passed: {dropout}\")\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, T, C = x.shape  # Batch, Sequence Length, Embedding Dimension\n",
        "        # print(f\"[HEAD] Input Shape: {x.shape} \\n Input Matrix: {x}\")\n",
        "\n",
        "        # Compute Q, K, V\n",
        "        q = self.W_q(x)  # (B, T, HEAD_SIZE)\n",
        "        k = self.W_k(x)  # (B, T, HEAD_SIZE)\n",
        "        v = self.W_v(x)  # (B, T, HEAD_SIZE)\n",
        "        # print(f\"\\n[HEAD] Q Matrix: {q}\")\n",
        "        # print(f\"[HEAD] K Matrix: {k}\")\n",
        "        # print(f\"[HEAD] V Matrix: {v}\")\n",
        "\n",
        "        # Compute scaled dot-product attention scores\n",
        "        sims = torch.matmul(q, k.transpose(-2, -1)) * self.scale  # (B, T, T)\n",
        "        # print(f\"\\n[HEAD] Attention Scores Matrix: {sims}\")\n",
        "\n",
        "        # Apply mask if provided\n",
        "        if mask is not None:\n",
        "            sims = sims.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = F.softmax(sims, dim=-1)  # (B, T, T)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "        # print(f\"\\n[HEAD] Attention Weights Matrix: {attention_weights}\")\n",
        "\n",
        "        # Compute weighted sum of values\n",
        "        out = torch.matmul(attention_weights, v)  # (B, T, HEAD_SIZE)\n",
        "        # print(f\"\\n[HEAD] Output Matrix: {out}\")\n",
        "\n",
        "        return out\n",
        "\n",
        "# **Multi-Head Attention**\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-Head Self-Attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        num_heads (int): Number of attention heads.\n",
        "        dropout (float, optional): Dropout rate. Defaults to DROPOUT_RATE.\n",
        "\n",
        "    Attributes:\n",
        "        num_heads (int): Number of heads.\n",
        "        head_size (int): Size of each attention head (N_EMBD / num_heads).\n",
        "        heads (nn.ModuleList): List of `Head` modules for self-attention.\n",
        "        proj (nn.Linear): Final linear projection layer.\n",
        "        dropout (nn.Dropout): Dropout layer applied after projection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads=NUM_HEADS, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        # print(f\"Dropout Rate Passed: {dropout}\")\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = HEAD_SIZE  # Compute individual head size\n",
        "\n",
        "        # Create multiple attention heads\n",
        "        self.heads = nn.ModuleList([Head(self.head_size, dropout) for _ in range(num_heads)])\n",
        "\n",
        "        # Final projection layer\n",
        "        self.proj = nn.Linear(N_EMBD, N_EMBD)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None,):\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # print(f\"\\n[MHA] Input Shape: {x.shape}\")\n",
        "        # Compute attention for each head independently\n",
        "        heads_output = [h(x, mask) for h in self.heads]  # List of (B, T, head_size) tensors\n",
        "        # print(f\"\\n[MHA] Heads Output: {heads_output}\")\n",
        "\n",
        "        # Concatenate head outputs across embedding dimension\n",
        "        out = torch.cat(heads_output, dim=-1)   # (B, T, N_EMBD)\n",
        "        # print(f\"\\n[MHA] Concatenated Heads Output: {out}\")\n",
        "\n",
        "        # Apply final projection layer\n",
        "        out = self.proj(out)  # (B, T, N_EMBD)\n",
        "        # print(f\"\\n[MHA] Final Output After Projection: {out}\")\n",
        "\n",
        "        out = self.dropout(out)  # Apply dropout\n",
        "        # print(f\"\\n[MHA] Final Output After Dropout: {out}\")\n",
        "\n",
        "        return out\n",
        "\n",
        "# **Multi-Head Attention Helper**\n",
        "def multi_head_attention_helper(sample_x):\n",
        "    \"\"\"\n",
        "    Helper function to test Multi-Head Attention.\n",
        "    \"\"\"\n",
        "    we = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=N_EMBD)\n",
        "    pe = PositionEncoding(n_embd=N_EMBD, max_len=MAX_LEN)\n",
        "\n",
        "    word_embeddings = we(sample_x)  # Shape: (B, T, N_EMBD)\n",
        "    position_encoded_embeddings = pe(word_embeddings)\n",
        "\n",
        "    mha = MultiHeadAttention(NUM_HEADS)\n",
        "    output = mha(position_encoded_embeddings)\n",
        "\n",
        "    print(summary(mha))\n",
        "\n",
        "\n",
        "def multi_head_attention_graph():\n",
        "    from torchview import draw_graph\n",
        "    mha_model = MultiHeadAttention(num_heads=NUM_HEADS, dropout=DROPOUT_RATE)\n",
        "    input_size = (BATCH_SIZE, MAX_LEN, N_EMBD)\n",
        "    model_graph = draw_graph(mha_model, input_size=input_size, expand_nested=True)\n",
        "    return model_graph\n",
        "\n"
      ],
      "metadata": {
        "id": "SGFayCilzdXW"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention_helper(sample_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg8yGYQN7u7Z",
        "outputId": "3310775e-0ba6-4ff4-82bd-1161bc1ddc86"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "MultiHeadAttention                       --\n",
            "├─ModuleList: 1-1                        --\n",
            "│    └─Head: 2-1                         --\n",
            "│    │    └─Linear: 3-1                  2\n",
            "│    │    └─Linear: 3-2                  2\n",
            "│    │    └─Linear: 3-3                  2\n",
            "│    │    └─Dropout: 3-4                 --\n",
            "│    └─Head: 2-2                         --\n",
            "│    │    └─Linear: 3-5                  2\n",
            "│    │    └─Linear: 3-6                  2\n",
            "│    │    └─Linear: 3-7                  2\n",
            "│    │    └─Dropout: 3-8                 --\n",
            "├─Linear: 1-2                            6\n",
            "├─Dropout: 1-3                           --\n",
            "=================================================================\n",
            "Total params: 18\n",
            "Trainable params: 18\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_graph = multi_head_attention_graph()\n",
        "model_graph.visual_graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T-a4U4PVDb4J",
        "outputId": "780b006b-5c6d-475f-d770-10241a6cb762"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: model Pages: 1 -->\n<svg width=\"880pt\" height=\"889pt\"\n viewBox=\"0.00 0.00 880.00 889.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 885)\">\n<title>model</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-885 876,-885 876,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_2</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"20,-294 20,-841 432,-841 432,-294 20,-294\"/>\n<text text-anchor=\"middle\" x=\"41\" y=\"-827.4\" font-family=\"Times,serif\" font-size=\"12.00\">Head</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_3</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"440,-294 440,-841 852,-841 852,-294 440,-294\"/>\n<text text-anchor=\"middle\" x=\"461\" y=\"-827.4\" font-family=\"Times,serif\" font-size=\"12.00\">Head</text>\n</g>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"509,-881 361,-881 361,-849 509,-849 509,-881\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"361,-849 361,-881 444,-881 444,-849 361,-849\"/>\n<text text-anchor=\"start\" x=\"366\" y=\"-868\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"381\" y=\"-857\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"444,-849 444,-881 509,-881 509,-849 444,-849\"/>\n<text text-anchor=\"start\" x=\"449\" y=\"-862.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"211.5,-734 28.5,-734 28.5,-692 211.5,-692 211.5,-734\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"29,-692 29,-734 82,-734 82,-692 29,-692\"/>\n<text text-anchor=\"start\" x=\"37\" y=\"-716\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"34\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"82,-713 82,-734 141,-734 141,-713 82,-713\"/>\n<text text-anchor=\"start\" x=\"93\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"141,-713 141,-734 212,-734 212,-713 141,-713\"/>\n<text text-anchor=\"start\" x=\"146\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"82,-692 82,-713 141,-713 141,-692 82,-692\"/>\n<text text-anchor=\"start\" x=\"87\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"141,-692 141,-713 212,-713 212,-692 141,-692\"/>\n<text text-anchor=\"start\" x=\"146\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M360.95,-861.41C311.43,-858.61 251.39,-852.84 229,-841 187.1,-818.85 154.34,-773.36 136.08,-743.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"138.99,-741.3 130.89,-734.47 132.96,-744.86 138.99,-741.3\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"420.5,-812 237.5,-812 237.5,-770 420.5,-770 420.5,-812\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"238,-770 238,-812 291,-812 291,-770 238,-770\"/>\n<text text-anchor=\"start\" x=\"246\" y=\"-794\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"243\" y=\"-783\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"291,-791 291,-812 350,-812 350,-791 291,-791\"/>\n<text text-anchor=\"start\" x=\"302\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"350,-791 350,-812 421,-812 421,-791 350,-791\"/>\n<text text-anchor=\"start\" x=\"355\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"291,-770 291,-791 350,-791 350,-770 291,-770\"/>\n<text text-anchor=\"start\" x=\"296\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"350,-770 350,-791 421,-791 421,-770 350,-770\"/>\n<text text-anchor=\"start\" x=\"355\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M412.78,-848.91C399.56,-839.93 382.44,-828.3 367.12,-817.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"369.07,-814.99 358.83,-812.26 365.14,-820.78 369.07,-814.99\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"211.5,-422 28.5,-422 28.5,-380 211.5,-380 211.5,-422\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"29,-380 29,-422 82,-422 82,-380 29,-380\"/>\n<text text-anchor=\"start\" x=\"37\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"34\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"82,-401 82,-422 141,-422 141,-401 82,-401\"/>\n<text text-anchor=\"start\" x=\"93\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"141,-401 141,-422 212,-422 212,-401 141,-401\"/>\n<text text-anchor=\"start\" x=\"146\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"82,-380 82,-401 141,-401 141,-380 82,-380\"/>\n<text text-anchor=\"start\" x=\"87\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"141,-380 141,-401 212,-401 212,-380 141,-380\"/>\n<text text-anchor=\"start\" x=\"146\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 0&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>0&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M360.69,-863.02C289.26,-861.18 186.87,-855.92 150,-841 69.03,-808.23 0,-801.35 0,-714 0,-714 0,-714 0,-556 0,-502.03 46.43,-455.62 81.53,-428.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"83.86,-430.86 89.72,-422.03 79.64,-425.28 83.86,-430.86\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"631.5,-734 448.5,-734 448.5,-692 631.5,-692 631.5,-734\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"449,-692 449,-734 502,-734 502,-692 449,-692\"/>\n<text text-anchor=\"start\" x=\"457\" y=\"-716\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"454\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"502,-713 502,-734 561,-734 561,-713 502,-713\"/>\n<text text-anchor=\"start\" x=\"513\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"561,-713 561,-734 632,-734 632,-713 561,-713\"/>\n<text text-anchor=\"start\" x=\"566\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"502,-692 502,-713 561,-713 561,-692 502,-692\"/>\n<text text-anchor=\"start\" x=\"507\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"561,-692 561,-713 632,-713 632,-692 561,-692\"/>\n<text text-anchor=\"start\" x=\"566\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge13\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M445.65,-848.79C463.04,-823.94 497.83,-774.24 519.96,-742.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"522.97,-744.43 525.84,-734.23 517.24,-740.42 522.97,-744.43\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"772.5,-812 589.5,-812 589.5,-770 772.5,-770 772.5,-812\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"590,-770 590,-812 643,-812 643,-770 590,-770\"/>\n<text text-anchor=\"start\" x=\"598\" y=\"-794\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"595\" y=\"-783\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"643,-791 643,-812 702,-812 702,-791 643,-791\"/>\n<text text-anchor=\"start\" x=\"654\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"702,-791 702,-812 773,-812 773,-791 702,-791\"/>\n<text text-anchor=\"start\" x=\"707\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"643,-770 643,-791 702,-791 702,-770 643,-770\"/>\n<text text-anchor=\"start\" x=\"648\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"702,-770 702,-791 773,-791 773,-770 702,-770\"/>\n<text text-anchor=\"start\" x=\"707\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 0&#45;&gt;11 -->\n<g id=\"edge14\" class=\"edge\">\n<title>0&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M486.27,-848.99C519.88,-839.16 564.47,-826.11 602.5,-814.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"603.91,-818.21 612.52,-812.04 601.94,-811.49 603.91,-818.21\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"843.5,-422 660.5,-422 660.5,-380 843.5,-380 843.5,-422\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"661,-380 661,-422 714,-422 714,-380 661,-380\"/>\n<text text-anchor=\"start\" x=\"669\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"666\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"714,-401 714,-422 773,-422 773,-401 714,-401\"/>\n<text text-anchor=\"start\" x=\"725\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"773,-401 773,-422 844,-422 844,-401 773,-401\"/>\n<text text-anchor=\"start\" x=\"778\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"714,-380 714,-401 773,-401 773,-380 714,-380\"/>\n<text text-anchor=\"start\" x=\"719\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"773,-380 773,-401 844,-401 844,-380 773,-380\"/>\n<text text-anchor=\"start\" x=\"778\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 0&#45;&gt;12 -->\n<g id=\"edge15\" class=\"edge\">\n<title>0&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M509.09,-862.46C603.94,-859.96 758.85,-853.96 782,-841 842.37,-807.21 872,-783.18 872,-714 872,-714 872,-714 872,-556 872,-502.03 825.57,-455.62 790.47,-428.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"792.36,-425.28 782.28,-422.03 788.14,-430.86 792.36,-425.28\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"423.5,-656 174.5,-656 174.5,-614 423.5,-614 423.5,-656\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"175,-614 175,-656 228,-656 228,-614 175,-614\"/>\n<text text-anchor=\"start\" x=\"183\" y=\"-638\" font-family=\"Linux libertine\" font-size=\"10.00\">matmul</text>\n<text text-anchor=\"start\" x=\"180\" y=\"-627\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"228,-635 228,-656 287,-656 287,-635 228,-635\"/>\n<text text-anchor=\"start\" x=\"239\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"287,-635 287,-656 424,-656 424,-635 287,-635\"/>\n<text text-anchor=\"start\" x=\"292\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1), (4, 1, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"228,-614 228,-635 287,-635 287,-614 228,-614\"/>\n<text text-anchor=\"start\" x=\"233\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"287,-614 287,-635 424,-635 424,-614 287,-614\"/>\n<text text-anchor=\"start\" x=\"325\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge4\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M167.5,-691.83C190.45,-682.09 218.16,-670.32 242.22,-660.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"243.75,-663.26 251.59,-656.13 241.02,-656.82 243.75,-663.26\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"424.5,-734 229.5,-734 229.5,-692 424.5,-692 424.5,-734\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"230,-692 230,-734 295,-734 295,-692 230,-692\"/>\n<text text-anchor=\"start\" x=\"235\" y=\"-716\" font-family=\"Linux libertine\" font-size=\"10.00\">transpose</text>\n<text text-anchor=\"start\" x=\"241\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"295,-713 295,-734 354,-734 354,-713 295,-713\"/>\n<text text-anchor=\"start\" x=\"306\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"354,-713 354,-734 425,-734 425,-713 354,-713\"/>\n<text text-anchor=\"start\" x=\"359\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"295,-692 295,-713 354,-713 354,-692 295,-692\"/>\n<text text-anchor=\"start\" x=\"300\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"354,-692 354,-713 425,-713 425,-692 354,-692\"/>\n<text text-anchor=\"start\" x=\"359\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 1, 4) </text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M328.46,-769.63C328.26,-761.82 328.02,-752.73 327.79,-744.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"331.29,-744.06 327.53,-734.16 324.29,-744.25 331.29,-744.06\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"423.5,-344 174.5,-344 174.5,-302 423.5,-302 423.5,-344\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"175,-302 175,-344 228,-344 228,-302 175,-302\"/>\n<text text-anchor=\"start\" x=\"183\" y=\"-326\" font-family=\"Linux libertine\" font-size=\"10.00\">matmul</text>\n<text text-anchor=\"start\" x=\"180\" y=\"-315\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"228,-323 228,-344 287,-344 287,-323 228,-323\"/>\n<text text-anchor=\"start\" x=\"239\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"287,-323 287,-344 424,-344 424,-323 287,-323\"/>\n<text text-anchor=\"start\" x=\"292\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4), (4, 4, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"228,-302 228,-323 287,-323 287,-302 228,-302\"/>\n<text text-anchor=\"start\" x=\"233\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"287,-302 287,-323 424,-323 424,-302 287,-302\"/>\n<text text-anchor=\"start\" x=\"325\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 3&#45;&gt;9 -->\n<g id=\"edge6\" class=\"edge\">\n<title>3&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M167.5,-379.83C190.45,-370.09 218.16,-358.32 242.22,-348.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"243.75,-351.26 251.59,-344.13 241.02,-344.82 243.75,-351.26\"/>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M319.5,-691.63C316.55,-683.65 313.12,-674.33 309.91,-665.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"313.17,-664.33 306.43,-656.16 306.6,-666.75 313.17,-664.33\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"395.5,-578 212.5,-578 212.5,-536 395.5,-536 395.5,-578\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"213,-536 213,-578 266,-578 266,-536 213,-536\"/>\n<text text-anchor=\"start\" x=\"230\" y=\"-560\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"218\" y=\"-549\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"266,-557 266,-578 325,-578 325,-557 266,-557\"/>\n<text text-anchor=\"start\" x=\"277\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"325,-557 325,-578 396,-578 396,-557 325,-557\"/>\n<text text-anchor=\"start\" x=\"330\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"266,-536 266,-557 325,-557 325,-536 266,-536\"/>\n<text text-anchor=\"start\" x=\"271\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"325,-536 325,-557 396,-557 396,-536 325,-536\"/>\n<text text-anchor=\"start\" x=\"330\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M300.34,-613.63C300.85,-605.82 301.45,-596.73 302.01,-588.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"305.51,-588.37 302.67,-578.16 298.52,-587.91 305.51,-588.37\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"406.5,-500 223.5,-500 223.5,-458 406.5,-458 406.5,-500\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"224,-458 224,-500 277,-500 277,-458 224,-458\"/>\n<text text-anchor=\"start\" x=\"229\" y=\"-482\" font-family=\"Linux libertine\" font-size=\"10.00\">softmax</text>\n<text text-anchor=\"start\" x=\"229\" y=\"-471\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"277,-479 277,-500 336,-500 336,-479 277,-479\"/>\n<text text-anchor=\"start\" x=\"288\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"336,-479 336,-500 407,-500 407,-479 336,-479\"/>\n<text text-anchor=\"start\" x=\"341\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"277,-458 277,-479 336,-479 336,-458 277,-458\"/>\n<text text-anchor=\"start\" x=\"282\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"336,-458 336,-479 407,-479 407,-458 336,-458\"/>\n<text text-anchor=\"start\" x=\"341\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge9\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M306.95,-535.63C308.08,-527.82 309.4,-518.73 310.63,-510.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"314.11,-510.56 312.08,-500.16 307.19,-509.55 314.11,-510.56\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"412.5,-422 229.5,-422 229.5,-380 412.5,-380 412.5,-422\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"230,-380 230,-422 283,-422 283,-380 230,-380\"/>\n<text text-anchor=\"start\" x=\"235\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"235\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"283,-401 283,-422 342,-422 342,-401 283,-401\"/>\n<text text-anchor=\"start\" x=\"294\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"342,-401 342,-422 413,-422 413,-401 342,-401\"/>\n<text text-anchor=\"start\" x=\"347\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"283,-380 283,-401 342,-401 342,-380 283,-380\"/>\n<text text-anchor=\"start\" x=\"288\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"342,-380 342,-401 413,-401 413,-380 342,-380\"/>\n<text text-anchor=\"start\" x=\"347\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge10\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M316.61,-457.63C317.22,-449.82 317.94,-440.73 318.62,-432.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"322.11,-432.4 319.41,-422.16 315.13,-431.85 322.11,-432.4\"/>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge11\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M315.1,-379.63C312.82,-371.73 310.15,-362.53 307.66,-353.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"310.98,-352.79 304.84,-344.16 304.25,-354.74 310.98,-352.79\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"539.5,-266 332.5,-266 332.5,-224 539.5,-224 539.5,-266\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"333,-224 333,-266 386,-266 386,-224 333,-224\"/>\n<text text-anchor=\"start\" x=\"350\" y=\"-248\" font-family=\"Linux libertine\" font-size=\"10.00\">cat</text>\n<text text-anchor=\"start\" x=\"338\" y=\"-237\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"386,-245 386,-266 445,-266 445,-245 386,-245\"/>\n<text text-anchor=\"start\" x=\"397\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"445,-245 445,-266 540,-266 540,-245 445,-245\"/>\n<text text-anchor=\"start\" x=\"450\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (4, 4, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"386,-224 386,-245 445,-245 445,-224 386,-224\"/>\n<text text-anchor=\"start\" x=\"391\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"445,-224 445,-245 540,-245 540,-224 445,-224\"/>\n<text text-anchor=\"start\" x=\"462\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 9&#45;&gt;19 -->\n<g id=\"edge12\" class=\"edge\">\n<title>9&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M335.35,-301.83C352.23,-292.47 372.47,-281.24 390.36,-271.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"392.43,-274.17 399.48,-266.26 389.03,-268.05 392.43,-274.17\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"697.5,-656 448.5,-656 448.5,-614 697.5,-614 697.5,-656\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"449,-614 449,-656 502,-656 502,-614 449,-614\"/>\n<text text-anchor=\"start\" x=\"457\" y=\"-638\" font-family=\"Linux libertine\" font-size=\"10.00\">matmul</text>\n<text text-anchor=\"start\" x=\"454\" y=\"-627\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"502,-635 502,-656 561,-656 561,-635 502,-635\"/>\n<text text-anchor=\"start\" x=\"513\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"561,-635 561,-656 698,-656 698,-635 561,-635\"/>\n<text text-anchor=\"start\" x=\"566\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1), (4, 1, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"502,-614 502,-635 561,-635 561,-614 502,-614\"/>\n<text text-anchor=\"start\" x=\"507\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"561,-614 561,-635 698,-635 698,-614 561,-614\"/>\n<text text-anchor=\"start\" x=\"599\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 10&#45;&gt;14 -->\n<g id=\"edge16\" class=\"edge\">\n<title>10&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M548.84,-691.63C552.35,-683.56 556.45,-674.12 560.26,-665.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"563.47,-666.73 564.25,-656.16 557.05,-663.94 563.47,-666.73\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"844.5,-734 649.5,-734 649.5,-692 844.5,-692 844.5,-734\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"650,-692 650,-734 715,-734 715,-692 650,-692\"/>\n<text text-anchor=\"start\" x=\"655\" y=\"-716\" font-family=\"Linux libertine\" font-size=\"10.00\">transpose</text>\n<text text-anchor=\"start\" x=\"661\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"715,-713 715,-734 774,-734 774,-713 715,-713\"/>\n<text text-anchor=\"start\" x=\"726\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"774,-713 774,-734 845,-734 845,-713 774,-713\"/>\n<text text-anchor=\"start\" x=\"779\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"715,-692 715,-713 774,-713 774,-692 715,-692\"/>\n<text text-anchor=\"start\" x=\"720\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"774,-692 774,-713 845,-713 845,-692 774,-692\"/>\n<text text-anchor=\"start\" x=\"779\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 1, 4) </text>\n</g>\n<!-- 11&#45;&gt;13 -->\n<g id=\"edge17\" class=\"edge\">\n<title>11&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M698.69,-769.63C706.07,-761.13 714.77,-751.12 722.73,-741.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"725.58,-744 729.49,-734.16 720.29,-739.41 725.58,-744\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"697.5,-344 448.5,-344 448.5,-302 697.5,-302 697.5,-344\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"449,-302 449,-344 502,-344 502,-302 449,-302\"/>\n<text text-anchor=\"start\" x=\"457\" y=\"-326\" font-family=\"Linux libertine\" font-size=\"10.00\">matmul</text>\n<text text-anchor=\"start\" x=\"454\" y=\"-315\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"502,-323 502,-344 561,-344 561,-323 502,-323\"/>\n<text text-anchor=\"start\" x=\"513\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"561,-323 561,-344 698,-344 698,-323 561,-323\"/>\n<text text-anchor=\"start\" x=\"566\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4), (4, 4, 1) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"502,-302 502,-323 561,-323 561,-302 502,-302\"/>\n<text text-anchor=\"start\" x=\"507\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"561,-302 561,-323 698,-323 698,-302 561,-302\"/>\n<text text-anchor=\"start\" x=\"599\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 1) </text>\n</g>\n<!-- 12&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>12&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M704.5,-379.83C681.55,-370.09 653.84,-358.32 629.78,-348.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"630.98,-344.82 620.41,-344.13 628.25,-351.26 630.98,-344.82\"/>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge19\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M700.83,-691.83C678.62,-682.13 651.82,-670.43 628.5,-660.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"629.65,-656.92 619.09,-656.13 626.85,-663.34 629.65,-656.92\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"658.5,-578 475.5,-578 475.5,-536 658.5,-536 658.5,-578\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"476,-536 476,-578 529,-578 529,-536 476,-536\"/>\n<text text-anchor=\"start\" x=\"493\" y=\"-560\" font-family=\"Linux libertine\" font-size=\"10.00\">mul</text>\n<text text-anchor=\"start\" x=\"481\" y=\"-549\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"529,-557 529,-578 588,-578 588,-557 529,-557\"/>\n<text text-anchor=\"start\" x=\"540\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"588,-557 588,-578 659,-578 659,-557 588,-557\"/>\n<text text-anchor=\"start\" x=\"593\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"529,-536 529,-557 588,-557 588,-536 529,-536\"/>\n<text text-anchor=\"start\" x=\"534\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"588,-536 588,-557 659,-557 659,-536 588,-536\"/>\n<text text-anchor=\"start\" x=\"593\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge20\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M571.39,-613.63C570.78,-605.82 570.06,-596.73 569.38,-588.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"572.87,-587.85 568.59,-578.16 565.89,-588.4 572.87,-587.85\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"653.5,-500 470.5,-500 470.5,-458 653.5,-458 653.5,-500\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"471,-458 471,-500 524,-500 524,-458 471,-458\"/>\n<text text-anchor=\"start\" x=\"476\" y=\"-482\" font-family=\"Linux libertine\" font-size=\"10.00\">softmax</text>\n<text text-anchor=\"start\" x=\"476\" y=\"-471\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"524,-479 524,-500 583,-500 583,-479 524,-479\"/>\n<text text-anchor=\"start\" x=\"535\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"583,-479 583,-500 654,-500 654,-479 583,-479\"/>\n<text text-anchor=\"start\" x=\"588\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"524,-458 524,-479 583,-479 583,-458 524,-458\"/>\n<text text-anchor=\"start\" x=\"529\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"583,-458 583,-479 654,-479 654,-458 583,-458\"/>\n<text text-anchor=\"start\" x=\"588\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge21\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M565.66,-535.63C565.15,-527.82 564.55,-518.73 563.99,-510.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"567.48,-509.91 563.33,-500.16 560.49,-510.37 567.48,-509.91\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"642.5,-422 459.5,-422 459.5,-380 642.5,-380 642.5,-422\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"460,-380 460,-422 513,-422 513,-380 460,-380\"/>\n<text text-anchor=\"start\" x=\"465\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"465\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"513,-401 513,-422 572,-422 572,-401 513,-401\"/>\n<text text-anchor=\"start\" x=\"524\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"572,-401 572,-422 643,-422 643,-401 572,-401\"/>\n<text text-anchor=\"start\" x=\"577\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"513,-380 513,-401 572,-401 572,-380 513,-380\"/>\n<text text-anchor=\"start\" x=\"518\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"572,-380 572,-401 643,-401 643,-380 572,-380\"/>\n<text text-anchor=\"start\" x=\"577\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 4) </text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge22\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M559.05,-457.63C557.92,-449.82 556.6,-440.73 555.37,-432.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"558.81,-431.55 553.92,-422.16 551.89,-432.56 558.81,-431.55\"/>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge23\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M556.9,-379.63C559.18,-371.73 561.85,-362.53 564.34,-353.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"567.75,-354.74 567.16,-344.16 561.02,-352.79 567.75,-354.74\"/>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge24\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M536.65,-301.83C519.77,-292.47 499.53,-281.24 481.64,-271.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"482.97,-268.05 472.52,-266.26 479.57,-274.17 482.97,-268.05\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"527.5,-188 344.5,-188 344.5,-146 527.5,-146 527.5,-188\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"345,-146 345,-188 398,-188 398,-146 345,-146\"/>\n<text text-anchor=\"start\" x=\"353\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"350\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"398,-167 398,-188 457,-188 457,-167 398,-167\"/>\n<text text-anchor=\"start\" x=\"409\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"457,-167 457,-188 528,-188 528,-167 457,-167\"/>\n<text text-anchor=\"start\" x=\"462\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"398,-146 398,-167 457,-167 457,-146 398,-146\"/>\n<text text-anchor=\"start\" x=\"403\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"457,-146 457,-167 528,-167 528,-146 457,-146\"/>\n<text text-anchor=\"start\" x=\"462\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge25\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M436,-223.63C436,-215.82 436,-206.73 436,-198.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"439.5,-198.16 436,-188.16 432.5,-198.16 439.5,-198.16\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"527.5,-110 344.5,-110 344.5,-68 527.5,-68 527.5,-110\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"345,-68 345,-110 398,-110 398,-68 345,-68\"/>\n<text text-anchor=\"start\" x=\"350\" y=\"-92\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"350\" y=\"-81\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"398,-89 398,-110 457,-110 457,-89 398,-89\"/>\n<text text-anchor=\"start\" x=\"409\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"457,-89 457,-110 528,-110 528,-89 457,-89\"/>\n<text text-anchor=\"start\" x=\"462\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"398,-68 398,-89 457,-89 457,-68 398,-68\"/>\n<text text-anchor=\"start\" x=\"403\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"457,-68 457,-89 528,-89 528,-68 457,-68\"/>\n<text text-anchor=\"start\" x=\"462\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge26\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M436,-145.63C436,-137.82 436,-128.73 436,-120.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"439.5,-120.16 436,-110.16 432.5,-120.16 439.5,-120.16\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"513,-32 359,-32 359,0 513,0 513,-32\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"359,0 359,-32 448,-32 448,0 359,0\"/>\n<text text-anchor=\"start\" x=\"364\" y=\"-19\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"382\" y=\"-8\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"448,0 448,-32 513,-32 513,0 448,0\"/>\n<text text-anchor=\"start\" x=\"453\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2)</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge27\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M436,-67.84C436,-59.89 436,-50.66 436,-42.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"439.5,-42.24 436,-32.24 432.5,-42.24 439.5,-42.24\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d3d16502490>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together"
      ],
      "metadata": {
        "id": "OQK_Ttog3Ter"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as L\n",
        "from torch.optim import Adam\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\"A simple 2-layer feed-forward network with ReLU activation.\n",
        "\n",
        "    Args:\n",
        "        N_EMBD (int): Embedding dimension.\n",
        "        dropout (float): Dropout rate for regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, N_EMBD, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=N_EMBD, out_features=4 * N_EMBD),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4 * N_EMBD, out_features=N_EMBD),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass for the feed-forward network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (B, T, N_EMBD).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of the same shape as input.\n",
        "        \"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"A single Transformer block containing Multi-Head Attention and Feed-Forward layers.\n",
        "\n",
        "    Args:\n",
        "        N_EMBD (int): Embedding dimension.\n",
        "        HEAD_SIZE (int): Size of each attention head.\n",
        "        dropout (float): Dropout rate for regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, N_EMBD, HEAD_SIZE, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        self.sa = MultiHeadAttention(NUM_HEADS)  # Multi-Head Attention layer\n",
        "        self.ffwd = FeedFoward(N_EMBD, dropout)  # Feed-Forward Network\n",
        "        self.ln1 = nn.LayerNorm(N_EMBD)  # Layer Normalization before MHA\n",
        "        self.ln2 = nn.LayerNorm(N_EMBD)  # Layer Normalization before Feed-Forward\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass of the Transformer block.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (B, T, N_EMBD).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of the same shape as input.\n",
        "        \"\"\"\n",
        "        x = x + self.sa(self.ln1(x))  # Add residual connection\n",
        "        x = x + self.ffwd(self.ln2(x))  # Add residual connection\n",
        "        return x\n",
        "\n",
        "class DecoderOnlyTransformer(L.LightningModule):\n",
        "    \"\"\"A GPT-style decoder-only Transformer for text generation.\n",
        "\n",
        "    Args:\n",
        "        num_tokens (int): Vocabulary size.\n",
        "        n_embd (int): Embedding dimension.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        num_layers (int): Number of Transformer blocks.\n",
        "        max_len (int): Maximum sequence length.\n",
        "        dropout (float): Dropout rate for regularization.\n",
        "        learning_rate (float): Learning rate for optimization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_tokens=VOCAB_SIZE, n_embd=N_EMBD, num_heads=NUM_HEADS, num_layers=NUM_LAYERS, max_len=MAX_LEN, dropout=DROPOUT_RATE, learning_rate=0.001):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        L.seed_everything(seed=42)\n",
        "\n",
        "        # Hyperparameters for logging\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Embedding Layers\n",
        "        self.token_embedding = nn.Embedding(num_embeddings=num_tokens, embedding_dim=n_embd)\n",
        "        self.position_encoding = PositionEncoding(n_embd=n_embd, max_len=max_len)\n",
        "\n",
        "        # Transformer Blocks\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, num_heads, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        # Final Layer Norm & Output Projection\n",
        "        self.ln_f = nn.LayerNorm(N_EMBD)\n",
        "        self.fc_layer = nn.Linear(N_EMBD, num_tokens)\n",
        "\n",
        "        # Loss Function\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        \"\"\"Forward pass of the Decoder Transformer.\n",
        "\n",
        "        Args:\n",
        "            token_ids (torch.Tensor): Input tensor of token IDs (B, T).\n",
        "            targets (torch.Tensor, optional): Target token IDs for loss calculation.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (logits, loss) where:\n",
        "                - logits (torch.Tensor): Model predictions of shape (B, T, num_tokens).\n",
        "                - loss (torch.Tensor or None): Cross-entropy loss if targets are provided.\n",
        "        \"\"\"\n",
        "        B, T = token_ids.shape  # Batch size, sequence length\n",
        "\n",
        "        # Token & Position Embeddings\n",
        "        tok_emb = self.token_embedding(token_ids)  # (B, T, N_EMBD)\n",
        "        pos_emb = self.position_encoding(tok_emb)  # (B, T, N_EMBD)\n",
        "\n",
        "        # Apply Transformer Blocks\n",
        "        x = self.blocks(pos_emb)  # (B, T, N_EMBD)\n",
        "        x = self.ln_f(x)  # (B, T, N_EMBD)\n",
        "\n",
        "        # Compute Logits\n",
        "        logits = self.fc_layer(x)  # (B, T, num_tokens)\n",
        "\n",
        "        # Compute Loss if Targets are Given\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            logits = logits.view(B * T, -1)  # Reshape logits to (B*T, num_tokens)\n",
        "            targets = targets.view(B * T)  # Reshape targets to (B*T)\n",
        "            loss = self.loss(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configures the optimizer for training.\n",
        "\n",
        "        Returns:\n",
        "            torch.optim.Adam: Adam optimizer with the given learning rate.\n",
        "        \"\"\"\n",
        "        return Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"Performs a single training step.\n",
        "\n",
        "        Args:\n",
        "            batch (tuple): Input tokens and target tokens.\n",
        "            batch_idx (int): Batch index (not used).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Training loss.\n",
        "        \"\"\"\n",
        "        input_tokens, labels = batch  # Collect input\n",
        "        logits, loss = self.forward(input_tokens, labels)  # Forward pass\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)  # Log loss to progress bar\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"Performs a single validation step.\n",
        "\n",
        "        Args:\n",
        "            batch (tuple): Input tokens and target tokens.\n",
        "            batch_idx (int): Batch index (not used).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Validation loss.\n",
        "        \"\"\"\n",
        "        input_tokens, labels = batch\n",
        "        logits, loss = self.forward(input_tokens, labels)\n",
        "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)  # Log validation loss\n",
        "        return loss\n",
        "\n",
        "def transformer_graph():\n",
        "    from torchview import draw_graph\n",
        "    model = DecoderOnlyTransformer(\n",
        "        num_tokens=VOCAB_SIZE,\n",
        "        n_embd=N_EMBD,\n",
        "        num_heads=NUM_HEADS,\n",
        "        num_layers=NUM_LAYERS,\n",
        "        max_len=MAX_LEN,\n",
        "        dropout=DROPOUT_RATE,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # Define dummy input (batch_size=4, sequence_length=6)\n",
        "    dummy_input = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, MAX_LEN))\n",
        "    model_graph = draw_graph(model, input_data=(dummy_input,), expand_nested=True)\n",
        "    return model_graph\n"
      ],
      "metadata": {
        "id": "QJgg9NH3N-do"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_graph = transformer_graph()\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z9TBv09-yBXK",
        "outputId": "aa2adf2a-6e97-4c42-e2cb-30e4a917f3a8"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: model Pages: 1 -->\n<svg width=\"276pt\" height=\"1037pt\"\n viewBox=\"0.00 0.00 276.16 1037.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.74 0.74) rotate(0) translate(4 1391)\">\n<title>model</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1391 367.5,-1391 367.5,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_2</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-208 8,-1191 302,-1191 302,-208 8,-208\"/>\n<text text-anchor=\"middle\" x=\"41\" y=\"-1177.4\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_3</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"22,-693 22,-1162 288,-1162 288,-693 22,-693\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-1148.4\" font-family=\"Times,serif\" font-size=\"12.00\">Block</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_4</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-216 16,-685 282,-685 282,-216 16,-216\"/>\n<text text-anchor=\"middle\" x=\"38.5\" y=\"-671.4\" font-family=\"Times,serif\" font-size=\"12.00\">Block</text>\n</g>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"310,-1387 180,-1387 180,-1355 310,-1355 310,-1387\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"180,-1355 180,-1387 263,-1387 263,-1355 180,-1355\"/>\n<text text-anchor=\"start\" x=\"185\" y=\"-1374\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"200\" y=\"-1363\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"263,-1355 263,-1387 310,-1387 310,-1355 263,-1355\"/>\n<text text-anchor=\"start\" x=\"268\" y=\"-1368.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"342.5,-1319 147.5,-1319 147.5,-1277 342.5,-1277 342.5,-1319\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"148,-1277 148,-1319 213,-1319 213,-1277 148,-1277\"/>\n<text text-anchor=\"start\" x=\"153\" y=\"-1301\" font-family=\"Linux libertine\" font-size=\"10.00\">Embedding</text>\n<text text-anchor=\"start\" x=\"159\" y=\"-1290\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"213,-1298 213,-1319 272,-1319 272,-1298 213,-1298\"/>\n<text text-anchor=\"start\" x=\"224\" y=\"-1306\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"272,-1298 272,-1319 343,-1319 343,-1298 272,-1298\"/>\n<text text-anchor=\"start\" x=\"286\" y=\"-1306\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"213,-1277 213,-1298 272,-1298 272,-1277 213,-1277\"/>\n<text text-anchor=\"start\" x=\"218\" y=\"-1285\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"272,-1277 272,-1298 343,-1298 343,-1277 272,-1277\"/>\n<text text-anchor=\"start\" x=\"277\" y=\"-1285\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M245,-1354.94C245,-1347.45 245,-1338.12 245,-1329.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.5,-1329.16 245,-1319.16 241.5,-1329.16 248.5,-1329.16\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"363.5,-1241 126.5,-1241 126.5,-1199 363.5,-1199 363.5,-1241\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"127,-1199 127,-1241 234,-1241 234,-1199 127,-1199\"/>\n<text text-anchor=\"start\" x=\"132\" y=\"-1223\" font-family=\"Linux libertine\" font-size=\"10.00\">PositionEncoding</text>\n<text text-anchor=\"start\" x=\"159\" y=\"-1212\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"234,-1220 234,-1241 293,-1241 293,-1220 234,-1220\"/>\n<text text-anchor=\"start\" x=\"245\" y=\"-1228\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"293,-1220 293,-1241 364,-1241 364,-1220 293,-1220\"/>\n<text text-anchor=\"start\" x=\"298\" y=\"-1228\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"234,-1199 234,-1220 293,-1220 293,-1199 234,-1199\"/>\n<text text-anchor=\"start\" x=\"239\" y=\"-1207\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"293,-1199 293,-1220 364,-1220 364,-1199 293,-1199\"/>\n<text text-anchor=\"start\" x=\"298\" y=\"-1207\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M245,-1276.63C245,-1268.82 245,-1259.73 245,-1251.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.5,-1251.16 245,-1241.16 241.5,-1251.16 248.5,-1251.16\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"266.5,-1133 71.5,-1133 71.5,-1091 266.5,-1091 266.5,-1133\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"72,-1091 72,-1133 137,-1133 137,-1091 72,-1091\"/>\n<text text-anchor=\"start\" x=\"77\" y=\"-1115\" font-family=\"Linux libertine\" font-size=\"10.00\">LayerNorm</text>\n<text text-anchor=\"start\" x=\"83\" y=\"-1104\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"137,-1112 137,-1133 196,-1133 196,-1112 137,-1112\"/>\n<text text-anchor=\"start\" x=\"148\" y=\"-1120\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"196,-1112 196,-1133 267,-1133 267,-1112 196,-1112\"/>\n<text text-anchor=\"start\" x=\"201\" y=\"-1120\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"137,-1091 137,-1112 196,-1112 196,-1091 137,-1091\"/>\n<text text-anchor=\"start\" x=\"142\" y=\"-1099\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"196,-1091 196,-1112 267,-1112 267,-1091 196,-1091\"/>\n<text text-anchor=\"start\" x=\"201\" y=\"-1099\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M230.35,-1198.56C218.71,-1182.33 202.3,-1159.44 189.38,-1141.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"192.02,-1139.1 183.35,-1133.02 186.33,-1143.18 192.02,-1139.1\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"268.5,-977 61.5,-977 61.5,-935 268.5,-935 268.5,-977\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"62,-935 62,-977 115,-977 115,-935 62,-935\"/>\n<text text-anchor=\"start\" x=\"79\" y=\"-959\" font-family=\"Linux libertine\" font-size=\"10.00\">add</text>\n<text text-anchor=\"start\" x=\"67\" y=\"-948\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"115,-956 115,-977 174,-977 174,-956 115,-956\"/>\n<text text-anchor=\"start\" x=\"126\" y=\"-964\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-956 174,-977 269,-977 269,-956 174,-956\"/>\n<text text-anchor=\"start\" x=\"179\" y=\"-964\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"115,-935 115,-956 174,-956 174,-935 115,-935\"/>\n<text text-anchor=\"start\" x=\"120\" y=\"-943\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"174,-935 174,-956 269,-956 269,-935 174,-935\"/>\n<text text-anchor=\"start\" x=\"191\" y=\"-943\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 2&#45;&gt;5 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M269.8,-1198.98C271.82,-1196.48 273.62,-1193.81 275,-1191 310.04,-1119.84 330.92,-1079.7 288,-1013 279.46,-999.73 266.92,-989.56 253.06,-981.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"254.29,-978.49 243.8,-977.02 251.08,-984.71 254.29,-978.49\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"279.5,-1055 30.5,-1055 30.5,-1013 279.5,-1013 279.5,-1055\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"31,-1013 31,-1055 150,-1055 150,-1013 31,-1013\"/>\n<text text-anchor=\"start\" x=\"36\" y=\"-1037\" font-family=\"Linux libertine\" font-size=\"10.00\">MultiHeadAttention</text>\n<text text-anchor=\"start\" x=\"69\" y=\"-1026\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"150,-1034 150,-1055 209,-1055 209,-1034 150,-1034\"/>\n<text text-anchor=\"start\" x=\"161\" y=\"-1042\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"209,-1034 209,-1055 280,-1055 280,-1034 209,-1034\"/>\n<text text-anchor=\"start\" x=\"214\" y=\"-1042\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"150,-1013 150,-1034 209,-1034 209,-1013 150,-1013\"/>\n<text text-anchor=\"start\" x=\"155\" y=\"-1021\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"209,-1013 209,-1034 280,-1034 280,-1013 209,-1013\"/>\n<text text-anchor=\"start\" x=\"214\" y=\"-1021\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165.25,-1090.63C163.81,-1082.82 162.13,-1073.73 160.56,-1065.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.97,-1064.36 158.71,-1055.16 157.08,-1065.63 163.97,-1064.36\"/>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.68,-1012.63C158.71,-1004.82 159.9,-995.73 161.03,-987.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"164.51,-987.53 162.35,-977.16 157.57,-986.62 164.51,-987.53\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"239.5,-899 44.5,-899 44.5,-857 239.5,-857 239.5,-899\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"45,-857 45,-899 110,-899 110,-857 45,-857\"/>\n<text text-anchor=\"start\" x=\"50\" y=\"-881\" font-family=\"Linux libertine\" font-size=\"10.00\">LayerNorm</text>\n<text text-anchor=\"start\" x=\"56\" y=\"-870\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110,-878 110,-899 169,-899 169,-878 110,-878\"/>\n<text text-anchor=\"start\" x=\"121\" y=\"-886\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"169,-878 169,-899 240,-899 240,-878 169,-878\"/>\n<text text-anchor=\"start\" x=\"174\" y=\"-886\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"110,-857 110,-878 169,-878 169,-857 110,-857\"/>\n<text text-anchor=\"start\" x=\"115\" y=\"-865\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"169,-857 169,-878 240,-878 240,-857 169,-857\"/>\n<text text-anchor=\"start\" x=\"174\" y=\"-865\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158.84,-934.63C156.45,-926.73 153.66,-917.53 151.05,-908.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"154.35,-907.72 148.1,-899.16 147.65,-909.74 154.35,-907.72\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"272.5,-743 65.5,-743 65.5,-701 272.5,-701 272.5,-743\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"66,-701 66,-743 119,-743 119,-701 66,-701\"/>\n<text text-anchor=\"start\" x=\"83\" y=\"-725\" font-family=\"Linux libertine\" font-size=\"10.00\">add</text>\n<text text-anchor=\"start\" x=\"71\" y=\"-714\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-722 119,-743 178,-743 178,-722 119,-722\"/>\n<text text-anchor=\"start\" x=\"130\" y=\"-730\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"178,-722 178,-743 273,-743 273,-722 178,-722\"/>\n<text text-anchor=\"start\" x=\"183\" y=\"-730\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-701 119,-722 178,-722 178,-701 119,-701\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-709\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"178,-701 178,-722 273,-722 273,-701 178,-701\"/>\n<text text-anchor=\"start\" x=\"195\" y=\"-709\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 5&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M210.59,-934.94C225.15,-926.12 239.64,-914.24 248,-899 264.67,-868.59 249.56,-855.68 250,-821 250.24,-802.33 258.67,-795.53 250,-779 243.67,-766.93 233.44,-756.95 222.34,-748.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"223.99,-745.83 213.73,-743.17 220.1,-751.64 223.99,-745.83\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"240.5,-821 39.5,-821 39.5,-779 240.5,-779 240.5,-821\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"40,-779 40,-821 111,-821 111,-779 40,-779\"/>\n<text text-anchor=\"start\" x=\"45\" y=\"-803\" font-family=\"Linux libertine\" font-size=\"10.00\">FeedFoward</text>\n<text text-anchor=\"start\" x=\"54\" y=\"-792\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"111,-800 111,-821 170,-821 170,-800 111,-800\"/>\n<text text-anchor=\"start\" x=\"122\" y=\"-808\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170,-800 170,-821 241,-821 241,-800 170,-800\"/>\n<text text-anchor=\"start\" x=\"175\" y=\"-808\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"111,-779 111,-800 170,-800 170,-779 111,-779\"/>\n<text text-anchor=\"start\" x=\"116\" y=\"-787\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170,-779 170,-800 241,-800 241,-779 170,-779\"/>\n<text text-anchor=\"start\" x=\"175\" y=\"-787\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge9\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M141.46,-856.63C141.26,-848.82 141.02,-839.73 140.79,-831.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"144.29,-831.06 140.53,-821.16 137.29,-831.25 144.29,-831.06\"/>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge10\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M147.77,-778.63C150.82,-770.65 154.38,-761.33 157.7,-752.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161.01,-753.75 161.31,-743.16 154.47,-751.25 161.01,-753.75\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"253.5,-656 58.5,-656 58.5,-614 253.5,-614 253.5,-656\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"59,-614 59,-656 124,-656 124,-614 59,-614\"/>\n<text text-anchor=\"start\" x=\"64\" y=\"-638\" font-family=\"Linux libertine\" font-size=\"10.00\">LayerNorm</text>\n<text text-anchor=\"start\" x=\"70\" y=\"-627\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-635 124,-656 183,-656 183,-635 124,-635\"/>\n<text text-anchor=\"start\" x=\"135\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"183,-635 183,-656 254,-656 254,-635 183,-635\"/>\n<text text-anchor=\"start\" x=\"188\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124,-614 124,-635 183,-635 183,-614 124,-614\"/>\n<text text-anchor=\"start\" x=\"129\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"183,-614 183,-635 254,-635 254,-614 183,-614\"/>\n<text text-anchor=\"start\" x=\"188\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge11\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165.92,-700.86C164.34,-690.56 162.39,-677.81 160.64,-666.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"164.08,-665.65 159.1,-656.29 157.16,-666.71 164.08,-665.65\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"262.5,-500 55.5,-500 55.5,-458 262.5,-458 262.5,-500\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"56,-458 56,-500 109,-500 109,-458 56,-458\"/>\n<text text-anchor=\"start\" x=\"73\" y=\"-482\" font-family=\"Linux libertine\" font-size=\"10.00\">add</text>\n<text text-anchor=\"start\" x=\"61\" y=\"-471\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-479 109,-500 168,-500 168,-479 109,-479\"/>\n<text text-anchor=\"start\" x=\"120\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"168,-479 168,-500 263,-500 263,-479 168,-479\"/>\n<text text-anchor=\"start\" x=\"173\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-458 109,-479 168,-479 168,-458 109,-458\"/>\n<text text-anchor=\"start\" x=\"114\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"168,-458 168,-479 263,-479 263,-458 168,-458\"/>\n<text text-anchor=\"start\" x=\"185\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 8&#45;&gt;11 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M242.9,-700.98C250.1,-696.65 256.69,-691.39 262,-685 304.69,-633.6 318.16,-592.19 282,-536 273.46,-522.73 260.92,-512.56 247.06,-504.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.29,-501.49 237.8,-500.02 245.08,-507.71 248.29,-501.49\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"273.5,-578 24.5,-578 24.5,-536 273.5,-536 273.5,-578\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"25,-536 25,-578 144,-578 144,-536 25,-536\"/>\n<text text-anchor=\"start\" x=\"30\" y=\"-560\" font-family=\"Linux libertine\" font-size=\"10.00\">MultiHeadAttention</text>\n<text text-anchor=\"start\" x=\"63\" y=\"-549\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"144,-557 144,-578 203,-578 203,-557 144,-557\"/>\n<text text-anchor=\"start\" x=\"155\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"203,-557 203,-578 274,-578 274,-557 203,-557\"/>\n<text text-anchor=\"start\" x=\"208\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"144,-536 144,-557 203,-557 203,-536 144,-536\"/>\n<text text-anchor=\"start\" x=\"149\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"203,-536 203,-557 274,-557 274,-536 203,-536\"/>\n<text text-anchor=\"start\" x=\"208\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge13\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.12,-613.63C153.4,-605.82 152.57,-596.73 151.78,-588.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"155.26,-587.8 150.86,-578.16 148.29,-588.44 155.26,-587.8\"/>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge14\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M151.68,-535.63C152.71,-527.82 153.9,-518.73 155.03,-510.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"158.51,-510.53 156.35,-500.16 151.57,-509.62 158.51,-510.53\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"225.5,-422 30.5,-422 30.5,-380 225.5,-380 225.5,-422\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"31,-380 31,-422 96,-422 96,-380 31,-380\"/>\n<text text-anchor=\"start\" x=\"36\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">LayerNorm</text>\n<text text-anchor=\"start\" x=\"42\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"96,-401 96,-422 155,-422 155,-401 96,-401\"/>\n<text text-anchor=\"start\" x=\"107\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"155,-401 155,-422 226,-422 226,-401 155,-401\"/>\n<text text-anchor=\"start\" x=\"160\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"96,-380 96,-401 155,-401 155,-380 96,-380\"/>\n<text text-anchor=\"start\" x=\"101\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"155,-380 155,-401 226,-401 226,-380 155,-380\"/>\n<text text-anchor=\"start\" x=\"160\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge15\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.69,-457.63C147.43,-449.65 143.63,-440.33 140.08,-431.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"143.24,-430.1 136.22,-422.16 136.76,-432.74 143.24,-430.1\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"252.5,-266 45.5,-266 45.5,-224 252.5,-224 252.5,-266\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"46,-224 46,-266 99,-266 99,-224 46,-224\"/>\n<text text-anchor=\"start\" x=\"63\" y=\"-248\" font-family=\"Linux libertine\" font-size=\"10.00\">add</text>\n<text text-anchor=\"start\" x=\"51\" y=\"-237\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"99,-245 99,-266 158,-266 158,-245 99,-245\"/>\n<text text-anchor=\"start\" x=\"110\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"158,-245 158,-266 253,-266 253,-245 158,-245\"/>\n<text text-anchor=\"start\" x=\"163\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"99,-224 99,-245 158,-245 158,-224 99,-224\"/>\n<text text-anchor=\"start\" x=\"104\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"158,-224 158,-245 253,-245 253,-224 158,-224\"/>\n<text text-anchor=\"start\" x=\"175\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 11&#45;&gt;14 -->\n<g id=\"edge16\" class=\"edge\">\n<title>11&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.21,-457.88C212.78,-448.89 226.4,-436.91 234,-422 258.21,-374.48 260.42,-348.89 235,-302 228.3,-289.65 217.57,-279.59 205.93,-271.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"207.65,-268.54 197.33,-266.12 203.89,-274.44 207.65,-268.54\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"226.5,-344 25.5,-344 25.5,-302 226.5,-302 226.5,-344\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"26,-302 26,-344 97,-344 97,-302 26,-302\"/>\n<text text-anchor=\"start\" x=\"31\" y=\"-326\" font-family=\"Linux libertine\" font-size=\"10.00\">FeedFoward</text>\n<text text-anchor=\"start\" x=\"40\" y=\"-315\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"97,-323 97,-344 156,-344 156,-323 97,-323\"/>\n<text text-anchor=\"start\" x=\"108\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"156,-323 156,-344 227,-344 227,-323 156,-323\"/>\n<text text-anchor=\"start\" x=\"161\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"97,-302 97,-323 156,-323 156,-302 97,-302\"/>\n<text text-anchor=\"start\" x=\"102\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"156,-302 156,-323 227,-323 227,-302 156,-302\"/>\n<text text-anchor=\"start\" x=\"161\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge17\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M127.46,-379.63C127.26,-371.82 127.02,-362.73 126.79,-354.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"130.29,-354.06 126.53,-344.16 123.29,-354.25 130.29,-354.06\"/>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge18\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M132.16,-301.63C134.55,-293.73 137.34,-284.53 139.95,-275.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"143.35,-276.74 142.9,-266.16 136.65,-274.72 143.35,-276.74\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"246.5,-188 51.5,-188 51.5,-146 246.5,-146 246.5,-188\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"52,-146 52,-188 117,-188 117,-146 52,-146\"/>\n<text text-anchor=\"start\" x=\"57\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">LayerNorm</text>\n<text text-anchor=\"start\" x=\"63\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"117,-167 117,-188 176,-188 176,-167 117,-167\"/>\n<text text-anchor=\"start\" x=\"128\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"176,-167 176,-188 247,-188 247,-167 176,-167\"/>\n<text text-anchor=\"start\" x=\"181\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"117,-146 117,-167 176,-167 176,-146 117,-146\"/>\n<text text-anchor=\"start\" x=\"122\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"176,-146 176,-167 247,-167 247,-146 176,-146\"/>\n<text text-anchor=\"start\" x=\"181\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge19\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149,-223.63C149,-215.82 149,-206.73 149,-198.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-198.16 149,-188.16 145.5,-198.16 152.5,-198.16\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"240.5,-110 57.5,-110 57.5,-68 240.5,-68 240.5,-110\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"58,-68 58,-110 111,-110 111,-68 58,-68\"/>\n<text text-anchor=\"start\" x=\"66\" y=\"-92\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"63\" y=\"-81\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"111,-89 111,-110 170,-110 170,-89 111,-89\"/>\n<text text-anchor=\"start\" x=\"122\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170,-89 170,-110 241,-110 241,-89 170,-89\"/>\n<text text-anchor=\"start\" x=\"175\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"111,-68 111,-89 170,-89 170,-68 111,-68\"/>\n<text text-anchor=\"start\" x=\"116\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"170,-68 170,-89 241,-89 241,-68 170,-68\"/>\n<text text-anchor=\"start\" x=\"175\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 6) </text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge20\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149,-145.63C149,-137.82 149,-128.73 149,-120.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-120.16 149,-110.16 145.5,-120.16 152.5,-120.16\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"226,-32 72,-32 72,0 226,0 226,-32\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"72,0 72,-32 161,-32 161,0 72,0\"/>\n<text text-anchor=\"start\" x=\"77\" y=\"-19\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"95\" y=\"-8\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"161,0 161,-32 226,-32 226,0 161,0\"/>\n<text text-anchor=\"start\" x=\"166\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(4, 4, 6)</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge21\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149,-67.84C149,-59.89 149,-50.66 149,-42.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-42.24 149,-32.24 145.5,-42.24 152.5,-42.24\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7d3d16668b10>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Generation"
      ],
      "metadata": {
        "id": "Dce0BOLm3ONG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = DecoderOnlyTransformer(num_tokens=VOCAB_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS84XbD9ZVDW",
        "outputId": "5bb30bcf-6897-4e9e-cd51-450e9d0108f7"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, seed_text, max_new_tokens=10):\n",
        "    \"\"\"\n",
        "    Generate text using trained model.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Transformer model.\n",
        "        seed_text: Input text to start generation.\n",
        "        max_new_tokens: Number of new tokens to generate.\n",
        "\n",
        "    Returns:\n",
        "        Generated text.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Convert input text to token IDs\n",
        "    input_tokens = torch.tensor([token_to_id[word] for word in seed_text.split() if word in token_to_id], dtype=torch.long).unsqueeze(0)\n",
        "    input_tokens = input_tokens.to(model.device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        logits, _ = model(input_tokens)  # Get model output\n",
        "        next_token = torch.argmax(logits[:, -1, :], dim=-1)  # Get highest probability token\n",
        "        input_tokens = torch.cat([input_tokens, next_token.unsqueeze(0)], dim=1)  # Append to input\n",
        "\n",
        "    generated_words = [id_to_token[i.item()] for i in input_tokens.squeeze()]\n",
        "    return \" \".join(generated_words)"
      ],
      "metadata": {
        "id": "GIKhAfEIa95-"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample batch from DataLoader\n",
        "sample_x, sample_y = next(iter(train_loader))\n",
        "\n",
        "# Ensure the input is moved to the same device as the model\n",
        "sample_x, sample_y = sample_x.to(model.device), sample_y.to(model.device)\n",
        "\n",
        "# Perform a forward pass\n",
        "logits, loss = model(sample_x, sample_y)\n",
        "\n",
        "print(f\"Output Logits Shape: {logits.shape}\")  # Expected: (BATCH_SIZE, MAX_LEN, VOCAB_SIZE)\n",
        "print(f\"Loss: {loss.item() if loss is not None else 'No Loss Computed'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKq_jB9EgnI3",
        "outputId": "db69cf54-4be1-4fa0-eb35-4a43bd1a2759"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Logits Shape: torch.Size([12, 6])\n",
            "Loss: 2.2246792316436768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Trainer\n",
        "trainer = L.Trainer(max_epochs=30, accelerator=\"cuda\")  # Set to \"gpu\" if CUDA is available\n",
        "\n",
        "# Train Model\n",
        "trainer.fit(model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813,
          "referenced_widgets": [
            "36a80f2945b94660968a3e037d3932cf",
            "65383508132747379d78390d73625ff7",
            "0e01499355304856add3e576a082551c",
            "f1f4fdf9643c490c8e5ca53b7919ecac",
            "79aa879b748040f680dc941b67dedc88",
            "383549218cc44bb0820e3422bec0c112",
            "efefe172ee5e41ea9b1c3305a94d16c4",
            "3a82e6eb5eea454cb5a1fedbb393801f",
            "ae71887733354305981fd91b3144f51d",
            "1549291f2ff344efa0916e963a048d19",
            "7da84ff2c62444a58dacf3c92563dd2c"
          ]
        },
        "id": "8BXW_A0Sg09K",
        "outputId": "094986c9-68de-4d8b-d1e2-1da952a3f9f2"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name              | Type             | Params | Mode\n",
            "--------------------------------------------------------------\n",
            "0 | dropout           | Dropout          | 0      | eval\n",
            "1 | token_embedding   | Embedding        | 12     | eval\n",
            "2 | position_encoding | PositionEncoding | 0      | eval\n",
            "3 | blocks            | Sequential       | 136    | eval\n",
            "4 | ln_f              | LayerNorm        | 4      | eval\n",
            "5 | fc_layer          | Linear           | 18     | eval\n",
            "6 | loss              | CrossEntropyLoss | 0      | eval\n",
            "--------------------------------------------------------------\n",
            "170       Trainable params\n",
            "0         Non-trainable params\n",
            "170       Total params\n",
            "0.001     Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "53        Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name              | Type             | Params | Mode\n",
            "--------------------------------------------------------------\n",
            "0 | dropout           | Dropout          | 0      | eval\n",
            "1 | token_embedding   | Embedding        | 12     | eval\n",
            "2 | position_encoding | PositionEncoding | 0      | eval\n",
            "3 | blocks            | Sequential       | 136    | eval\n",
            "4 | ln_f              | LayerNorm        | 4      | eval\n",
            "5 | fc_layer          | Linear           | 18     | eval\n",
            "6 | loss              | CrossEntropyLoss | 0      | eval\n",
            "--------------------------------------------------------------\n",
            "170       Trainable params\n",
            "0         Non-trainable params\n",
            "170       Total params\n",
            "0.001     Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "53        Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36a80f2945b94660968a3e037d3932cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Inference\n",
        "seed_text = \"I Love\"\n",
        "generated_text = generate_text(model, seed_text, max_new_tokens=2)\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MkrCHD3jlwQ",
        "outputId": "735131df-9f3c-4efc-d1dc-918e5d47bffc"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text: I Love Transformers Transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FINAL ARCHITECTURE:"
      ],
      "metadata": {
        "id": "-X9-cFUU3KLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.fx import symbolic_trace\n",
        "from torchinfo import summary\n",
        "\n",
        "class PositionEncoding(nn.Module):\n",
        "    def __init__(self, n_embd=N_EMBD, max_len=MAX_LEN):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, N_EMBD)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        embedding_index = torch.arange(start=0, end=N_EMBD, step=2).float()\n",
        "        div_term = 1 / torch.tensor(10000.0) ** (embedding_index / N_EMBD)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, word_embeddings):\n",
        "        \"\"\"\n",
        "        Adds positional encoding to word embeddings.\n",
        "        Shapes:\n",
        "        - word_embeddings: (B, T, C)\n",
        "        - position encoding: (T, C) → Needs to be reshaped for broadcasting\n",
        "        - final output: (B, T, C)\n",
        "        \"\"\"\n",
        "        return word_embeddings + self.pe[:word_embeddings.size(1), :].unsqueeze(0)\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\"Single self-attention head for Multi-Head Attention.\n",
        "\n",
        "    Args:\n",
        "        head_size (int): The size of each attention head (N_EMBD / NUM_HEADS).\n",
        "        dropout (float, optional): Dropout rate for regularization. Defaults to DROPOUT_RATE.\n",
        "\n",
        "    Attributes:\n",
        "        W_q (nn.Linear): Linear transformation for query matrix.\n",
        "        W_k (nn.Linear): Linear transformation for key matrix.\n",
        "        W_v (nn.Linear): Linear transformation for value matrix.\n",
        "        scale (float): Scaling factor for dot-product attention.\n",
        "        dropout (nn.Dropout): Dropout layer for attention scores.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        self.W_q = nn.Linear(in_features=N_EMBD, out_features=head_size, bias=False)\n",
        "        self.W_k = nn.Linear(in_features=N_EMBD, out_features=head_size, bias=False)\n",
        "        self.W_v = nn.Linear(in_features=N_EMBD, out_features=head_size, bias=False)\n",
        "\n",
        "        self.scale = head_size ** -0.5\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, T, C = x.shape\n",
        "        q = self.W_q(x)\n",
        "        k = self.W_k(x)\n",
        "        v = self.W_v(x)\n",
        "        sims = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            sims = sims.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attention_weights = F.softmax(sims, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "        out = torch.matmul(attention_weights, v)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-Head Self-Attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        num_heads (int): Number of attention heads.\n",
        "        dropout (float, optional): Dropout rate. Defaults to DROPOUT_RATE.\n",
        "\n",
        "    Attributes:\n",
        "        num_heads (int): Number of heads.\n",
        "        head_size (int): Size of each attention head (N_EMBD / num_heads).\n",
        "        heads (nn.ModuleList): List of `Head` modules for self-attention.\n",
        "        proj (nn.Linear): Final linear projection layer.\n",
        "        dropout (nn.Dropout): Dropout layer applied after projection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads=NUM_HEADS, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = HEAD_SIZE\n",
        "        self.heads = nn.ModuleList([Head(self.head_size, dropout) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(N_EMBD, N_EMBD)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None,):\n",
        "        heads_output = [h(x, mask) for h in self.heads]\n",
        "        out = torch.cat(heads_output, dim=-1)\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as L\n",
        "from torch.optim import Adam\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\"A simple 2-layer feed-forward network with ReLU activation.\n",
        "\n",
        "    Args:\n",
        "        N_EMBD (int): Embedding dimension.\n",
        "        dropout (float): Dropout rate for regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, N_EMBD, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=N_EMBD, out_features=4 * N_EMBD),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4 * N_EMBD, out_features=N_EMBD),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"A single Transformer block containing Multi-Head Attention and Feed-Forward layers.\n",
        "\n",
        "    Args:\n",
        "        N_EMBD (int): Embedding dimension.\n",
        "        HEAD_SIZE (int): Size of each attention head.\n",
        "        dropout (float): Dropout rate for regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, N_EMBD, HEAD_SIZE, dropout=DROPOUT_RATE):\n",
        "        super().__init__()\n",
        "        self.sa = MultiHeadAttention(NUM_HEADS)\n",
        "        self.ffwd = FeedFoward(N_EMBD, dropout)\n",
        "        self.ln1 = nn.LayerNorm(N_EMBD)\n",
        "        self.ln2 = nn.LayerNorm(N_EMBD)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class DecoderOnlyTransformer(L.LightningModule):\n",
        "    \"\"\"A GPT-style decoder-only Transformer for text generation.\n",
        "\n",
        "    Args:\n",
        "        num_tokens (int): Vocabulary size.\n",
        "        n_embd (int): Embedding dimension.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        num_layers (int): Number of Transformer blocks.\n",
        "        max_len (int): Maximum sequence length.\n",
        "        dropout (float): Dropout rate for regularization.\n",
        "        learning_rate (float): Learning rate for optimization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_tokens=VOCAB_SIZE, n_embd=N_EMBD, num_heads=NUM_HEADS, num_layers=NUM_LAYERS, max_len=MAX_LEN, dropout=DROPOUT_RATE, learning_rate=0.001):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        L.seed_everything(seed=42)\n",
        "        self.save_hyperparameters()\n",
        "        self.token_embedding = nn.Embedding(num_embeddings=num_tokens, embedding_dim=n_embd)\n",
        "        self.position_encoding = PositionEncoding(n_embd=n_embd, max_len=max_len)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, num_heads, dropout) for _ in range(num_layers)])\n",
        "        self.ln_f = nn.LayerNorm(N_EMBD)\n",
        "        self.fc_layer = nn.Linear(N_EMBD, num_tokens)\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, token_ids, targets=None):\n",
        "        B, T = token_ids.shape\n",
        "        tok_emb = self.token_embedding(token_ids)\n",
        "        pos_emb = self.position_encoding(tok_emb)\n",
        "        x = self.blocks(pos_emb)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.fc_layer(x)\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            logits = logits.view(B * T, -1)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = self.loss(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_tokens, labels = batch\n",
        "        logits, loss = self.forward(input_tokens, labels)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_tokens, labels = batch\n",
        "        logits, loss = self.forward(input_tokens, labels)\n",
        "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "BLOCK_SIZE = 4 # Context window size\n",
        "BATCH_SIZE = 4  # Number of sequences per batch (B)\n",
        "MAX_LEN = 4  # Maximum sequence length for positional encoding (T)\n",
        "N_EMBD = 2  # Embedding dimension (C) d_model\n",
        "NUM_HEADS = 2 # 2 heads\n",
        "HEAD_SIZE = N_EMBD // NUM_HEADS  # Each head gets a fraction of embedding size\n",
        "DROPOUT_RATE = 0.1\n",
        "NUM_LAYERS = 2\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "trainer = L.Trainer(max_epochs=30, accelerator=\"cuda\")\n",
        "trainer.fit(model, train_loader)\n"
      ],
      "metadata": {
        "id": "gotNp39gz_jc"
      },
      "execution_count": 134,
      "outputs": []
    }
  ]
}